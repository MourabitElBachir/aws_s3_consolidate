{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fives CortX / Data preparation / Minimize volume</h2>\n",
    "\n",
    "## Code Notebook\n",
    "\n",
    "**By :** MOURABIT El Bachir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Imports and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"CSV_to_ORC\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Read Milling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_milling = spark.read.csv(\"../csv_files_s3/milling_modes.csv\", header=True)\n",
    "df_milling.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Read Vibration_A_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_AB: string (nullable = true)\n",
      " |-- value_A: string (nullable = true)\n",
      " |-- value_B: string (nullable = true)\n",
      "\n",
      "+-------+-------+-------+\n",
      "|date_AB|value_A|value_B|\n",
      "+-------+-------+-------+\n",
      "|      2|   null|   null|\n",
      "|      2|   null|   null|\n",
      "|      2|   null|   null|\n",
      "|      2|   null|   null|\n",
      "|      2|   null|   null|\n",
      "|      2|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "|     20|   null|   null|\n",
      "+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vibration_A_B = spark \\\n",
    "                    .read \\\n",
    "                    .csv(\"../csv_files_s3/vibration_axis_A_axis_B/*.*\", header=True) \\\n",
    "                    .toDF(\"date_AB\", \"value_A\", \"value_B\") \\\n",
    "                    .orderBy('date_AB')\n",
    "                    \n",
    "df_vibration_A_B.printSchema()\n",
    "df_vibration_A_B.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Read Vibration_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- values3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vibration_C = spark.read.csv(\"../csv_files_s3/vibration_axis_C.csv\", header=True)\n",
    "df_vibration_C.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Read Vibration_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- values4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vibration_D = spark.read.csv(\"../csv_files_s3/vibration_axis_D.csv\", header=True)\n",
    "df_vibration_D.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Migrate from CSV to ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_milling.write.mode(\"overwrite\").orc(\"../orc_to_s3/milling_modes.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vibration_A_B.write.mode(\"overwrite\").orc(\"../orc_to_s3/vibration_axis_A_axis_B.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vibration_C.write.mode(\"overwrite\").orc(\"../orc_to_s3/vibration_axis_C.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vibration_D.write.mode(\"overwrite\").orc(\"../orc_to_s3/vibration_axis_D.orc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7- Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- values1: string (nullable = true)\n",
      " |-- values2: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                 _c0|             values1|             values2|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|2018-11-21 18:06:...|  -1.700976359316765|-0.46908177869076406|\n",
      "|2018-11-21 18:06:...| -0.3297466179063344| -0.1797920614084737|\n",
      "|2018-11-21 18:06:...|  -1.178325579046026| -0.4208986619048354|\n",
      "|2018-11-21 18:06:...| -1.0228619352056278| -0.5983779417665455|\n",
      "|2018-11-21 18:06:...| -0.5285685917851948| -0.3060502723631234|\n",
      "|2018-11-21 18:06:...| -0.8518715371757454| -0.5551414746568127|\n",
      "|2018-11-21 18:06:...|-0.35253491147863425| -0.3593343224872544|\n",
      "|2018-11-21 18:06:...| -1.2094980753115538|-0.17926240196702284|\n",
      "|2018-11-21 18:06:...|  -1.413347896002105| -0.5362140526295736|\n",
      "|2018-11-21 18:06:...|-0.22435992152724993|-0.18071471636144687|\n",
      "|2018-11-21 18:06:...| -1.1090106441480971| -0.5540198840650516|\n",
      "|2018-11-21 18:06:...|  0.3483839241377662|-0.43087187909932106|\n",
      "|2018-11-21 18:06:...| -0.4431730259715684| -0.3306206027406645|\n",
      "|2018-11-21 18:06:...|  -1.256248474337569| -0.5905750771606386|\n",
      "|2018-11-21 18:06:...| -0.6117840116248139| -0.4751167699957281|\n",
      "|2018-11-21 18:06:...|  0.6192000455720528| -0.5627282562640383|\n",
      "|2018-11-21 18:06:...|  0.5213293853917809|-0.49034118987911973|\n",
      "|2018-11-21 18:06:...|-0.38103114576425157|-0.20529731700678994|\n",
      "|2018-11-21 18:06:...| -0.7000867466720285| -0.2249795661948485|\n",
      "|2018-11-21 18:06:...|  0.3774537118907043|-0.34053680691917126|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vibration_A_B_df = spark \\\n",
    "                    .read \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .orc(\"../orc_to_s3/vibration_axis_A_axis_B.orc\")\n",
    "vibration_A_B_df.printSchema()\n",
    "vibration_A_B_df.show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
